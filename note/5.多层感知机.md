> 4.1
> 1. [4.1课后题](#4_1_课后题)
>
> 4.2 mlp-scratch
> 1. [4.2课后题](#4_2课后题)
>
> 4.3 mlp-concise
> 1. [4.3课后题](#4_3课后题)
>
> 4.4 underfit-overfit
> 1. [4.4课后题](#4_4课后题)
>
> 4.5 weight-decay
> 1. [4.5课后题](#4_5课后题)
>
> 4.6 dropout
> 1. [4.6课后题](#4_6课后题)
>
> 4.8
> 1. [4.8课后题](#4_8_课后题)
#### 为何要引入隐藏层
线性模型可能会出错，线性模型单调性但不是标准的线性相关。

    正相关：收入从0增加到5万，可能比从100万增加到105万带来更大的还款可能性。 处理这一问题的一种方法是对我们的数据进行预处理， 使线性变得更合理，如使用收入的对数作为我们的特征。

    违反单调性的例子：负相关我们可以使用与37摄氏度的距离作为特征。
 仿射变换（affine transformation）。 仿射变换的特点是通过加权和对特征进行线性变换（linear transformation）， 并通过偏置项来进行平移（translation）。

#### 多层感知机（MLP）
#### 为什么要引入非线性的激活函数（activation function）？ 
 多个隐藏层的堆叠等价于对输入数据应用多次线性变换，其等价于一个线性变换；为提高模型的表达能力。
> 激活函数的输出被称为活性值（activations）

#### 激活函数种类
1. **ReLU函数**        $\[ \text{ReLU}(x) = \max(x, 0) \]$;仅保留正元素并丢弃所有负元素。当输入为负时，ReLU函数的导数为0，而当输入为正时，ReLU函数的导数为1。
2. **参数化ReLU（Parameterized ReLU，pReLU） 函数** $\[ \text{pReLU}(x) = \max(0, x) + \alpha \min(0, x) \]$
3. **sigmoid函数**,(又称挤压函数（squashing function）)   $\[ \text{sigmoid}(x) = \frac{1}{1 + \exp(-x)} \]$  sigmoid函数将输入变换为区间(0, 1)上的输出。
> 注意其导数值的特称，两侧几乎为零，中间最大
4. **tanh函数** $\[ \text{tanh}(x) = \frac{1 - \exp(-2x)}{1 + \exp(-2x)} \]$  

#### 权重缩减（L2正则化）：防止过拟合
> 为了缓解过拟合

要保证权重向量比较小， 最常用方法是将其范数作为惩罚项加到最小化损失的问题中。

原理：将其（ $\| \mathbf{w} \|^2$ ）范数作为惩罚项加到最小化损失的问题中,通过函数与零的距离来衡量函数的复杂度;将原来的训练目标最小化训练标签上的预测损失， 调整为最小化预测损失和惩罚项之和。

$$
L(\mathbf{w}, b) + \frac{\lambda}{2} \|\mathbf{w}\|^2,
$$

 1. 使用L2范数的一个原因是它对权重向量的大分量施加了巨大的惩罚。 这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。;相比之下，L1惩罚会导致模型将权重集中在一小部分特征上， 而将其他权重清除为零。 这称为特征选择（feature selection），这可能是其他场景下需要的。
 2. L2正则化线性模型构成经典的岭回归（ridge regression）算法，L1 正则化线性回归是统计学中类似的基本模型， 通常被称为套索回归（lasso regression）

所以参数变化为：

$$
\begin{aligned}
\mathbf{w} & \leftarrow \left(1- \eta\lambda \right) \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right).
\end{aligned}
$$

#### 暂退法引入:对噪声有鲁棒性 
例如，当我们对图像进行分类时，我们预计向像素添加一些随机噪声应该是基本无影响的。

暂退法：从表面上看是在训练过程中丢弃（drop out）一些神经元。 在整个训练过程的每一次迭代中，**标准暂退法**包括在计算下一层之前将当前层中的一些节点置零。

注入噪声的方法：
1. 一种想法是以一种无偏向（unbiased）的方式注入噪声。 这样在固定住其他层时，每一层的期望值等于没有噪音时的值。

   他将高斯噪声添加到线性模型的输入中。 在每次训练迭代中，他将从均值为零的分布 $\epsilon \sim \mathcal{N}(0,\sigma^2)$ 采样噪声添加到输入x， 从而产生扰动点 $\mathbf{x}' = \mathbf{x} + \epsilon$ ， 预期是 $ E[\mathbf{x}'] = \mathbf{x} $ 。


##### 暂退法中的一系列问题（很重要）
1. 请问 dropout 公式那里，对于h，为什么要除以一个1-p.
   答：丢掉的一部分节点，需要通过保留的那部分找补回来，通过使数据的期望不变（靠1-p做到）做到。
2. 在用API简介实现暂退法时，为什么要自定义权重weight，却不重新定义bias
   答：参考一下nn.Linear()的文档，这个函数自动会对w和b进行uniform的初始化。这里是想要把w改成高斯分布才特意强调的。代码中 nn.Linear() 会把 w 进行 kaiming 正态分布初始化 是一种适用于 RELU 激活函数的初始化。

#### 初始化模型参数
首先，选择合适的函数或分布初始化参数是很有必要的，他与非线性激活函数相配合，eg：高斯分布与RELU函数配合，效果就不错

梯度爆炸，梯度过大，参数难稳定收敛；                    eg当模型含较多层，多个参数矩阵相乘，结果中每个元素都过大，优化器来不及收敛

梯度消失，梯度过小，参数几乎不移动，模型几乎不进化        eg：sigmoid（），当输入过大或者过小；改用relu

  **随机初始化是保证在进行优化前打破对称性的关键。**

> 那初始化参数有什么方法吗?

1. 若不指定，框架自动初始化
2. 正态分布
3. Xavier初始化：使分布满足一下条件

   Xavier初始化从均值为零，方差 $\sigma^2 = \frac{2}{n_\mathrm{in} + n_\mathrm{out}}$ 的高斯分布中采样权重。我们也可以将其改为选择从均匀分布中抽取权重时的方差。 注意均匀分布 $U(-a, a) $
的方差为 $\frac{a^2}{3}$。 将 $\frac{a^2}{3}$ 代入到 $\sigma^2$ 的条件中，将得到初始化值域：
$U\left(-\sqrt{\frac{6}{n_\mathrm{in} + n_\mathrm{out}}}, \sqrt{\frac{6}{n_\mathrm{in} + n_\mathrm{out}}}\right).$


**Xavier初始化表明，对于每一层，输出的方差不受输入数量的影响，任何梯度的方差不受输出数量的影响。**

## 4_1_课后题

#### 1. 计算pReLU激活函数的导数。
$$
\operatorname{pReLU}(x) = \max(0, x) + \alpha \min(0, x)
$$

 当x>0时，导数为1；其他为 $\alpha$



#### 证明 $\operatorname{tanh}(x) + 1 = 2 \operatorname{sigmoid}(2x)$。

1. 证明方法一：

![代码证明](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/1adda89556c34c0e9c7585e8fd3e5e34608ce1b6/picture/4.1.1%E8%AF%BE%E5%90%8E%E9%A2%98%E7%AC%AC%E4%B8%89%E9%97%AE.png)

2. 证明方法二：
要证明 $\tanh(x) + 1 = 2 \sigma(2x)$，我们可以使用双曲正切函数 $\tanh(x)$ 和 Sigmoid 函数 $\sigma(x)$ 的定义以及一些性质来进行证明。首先，让我们回顾一下这两个函数的定义：

1. 双曲正切函数 $\tanh(x)$ 的定义为：

$$
\[
\tanh(x) = \frac{\sinh(x)}{\cosh(x)} = \frac{e^x - e^{-x}}{e^x + e^{-x}}
\]
$$

2. Sigmoid 函数 $\sigma(x)$ 的定义为：

$$
\[
\sigma(x) = \frac{1}{1 + e^{-x}}
\]
$$

现在我们开始证明：

$$
\[
\begin{aligned}
\tanh(x) + 1 &= \frac{e^x - e^{-x}}{e^x + e^{-x}} + 1 \\
&= \frac{e^x - e^{-x} + e^x + e^{-x}}{e^x + e^{-x}} \\
&= \frac{2e^x}{e^x + e^{-x}} \\
&= 2\frac{e^x}{e^x(1 + e^{-2x})} \\
&= 2\frac{1}{1 + e^{-2x}} \\
&= 2 \sigma(2x)
\end{aligned}
\]
$$

在上述推导中，我们使用了双曲正切函数和 Sigmoid 函数的定义，以及双曲正切函数的另一种表示形式 \(\tanh(x) = \frac{2}{1 + e^{-2x}}\)。通过这些步骤，我们得出了 $\tanh(x) + 1 = 2 \sigma(2x)$ 的结论，完成了证明。

### 3.证明一个仅使用ReLU（或pReLU）的多层感知机构造了一个连续的分段线性函数。
> 根据评论区的大神讲解，获取一下信息
> 1. 含有非线性激活函数的多层感知机在有限空间内能逼近任意连续函数
> 2. 第二题的结论反过来也成立，任意一个连续的分段线性函数可以被使用ReLU（或pReLU）的多层感知机近似
> 
> **说明非线性激活函数的重要性，若没有，仅是线性变换不足以使模型完备**

### 4. 假设我们有一个非线性单元，将它一次应用于一个小批量的数据。这会导致什么样的问题？
> 根据评论区和GPT总结：
1. 批量归一化问题：如果对整个小批量数据进行批量归一化，即计算批量数据的均值和方差进行归一化操作，那么可能会导致归一化的效果不准确，因为每个样本可能具有不同的统计特征。这会影响批量归一化的稳定性和效果。
2. 梯度的不稳定性：非线性单元在反向传播时可能会导致梯度的不稳定性，特别是在深层网络中。这种不稳定性可能会导致梯度消失或梯度爆炸问题，使得模型的训练变得困难或者不稳定。
3. 计算效率：如果非线性单元的计算复杂度较高，一次应用于一个小批量的数据可能会导致计算量增加，影响模型的训练速度和效率。

## 4_2课后题

### 1. 在所有其他参数保持不变的情况下，更改超参数num_hiddens的值，并查看此超参数的变化对结果有何影响。确定此超参数的最佳值。
1. 128
   
   ![128](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/eb44f808dd3e924e3975b23aa7343e71ef6810e9/picture/4.2.1num_hiddens%3D128.png)
2. 256
   
   ![256](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/2d436fcb96755b522b968520114a64391595a5cf/picture/4.2.1num_hiddens%3D256.png)
   
3. 512

   ![512](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/12efd6cd18119f8b521115e2931bf5c804f78759/picture/4.2.1num_hiddens%3D512.png)
   
### 2. 尝试添加更多的隐藏层，并查看它对结果有何影响。
> 结论放前面：**增加了隐藏层，收敛变慢了**

1. 一层

![一层hiddnes](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/2d436fcb96755b522b968520114a64391595a5cf/picture/4.2.1num_hiddens%3D256.png)

2. 两层
``` py
#2024-4-20
#刘昊阳
num_inputs, num_outputs, num_hiddens,num_hiddens_2 = 784, 10, 128,64

W1 = nn.Parameter(torch.randn(
    num_inputs, num_hiddens, requires_grad=True) * 0.01)
b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))
W2 = nn.Parameter(torch.randn(
    num_hiddens, num_hiddens_2, requires_grad=True) * 0.01)
b2 = nn.Parameter(torch.zeros(num_hiddens_2, requires_grad=True))
W3 = nn.Parameter(torch.randn(
    num_hiddens_2, num_outputs, requires_grad=True) * 0.01)
b3 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))

params = [W1, b1, W2, b2,W3,b3]

def net(X):
    X = X.reshape((-1, num_inputs))
    H = relu(X@W1 + b1)  # 这里“@”代表矩阵乘法
    H2= relu(H@W2 + b2)
    return (H2@W3 + b3)
```
两层hiddens，256和64，epoch=10，lr=0.1

![两层hiddnes](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/9eae8ae78c12ae434f472d3304ac0ff8193e8180/picture/4.2.2%E4%B8%A4%E5%B1%82hidden64.png)

> **当隐藏层层数增加时，需要增大epoch，否则难收敛，效果不好；增加epoch后，效果会好**
> 见下图
3. 两层hiddens，256和64，epoch=20，lr=0.1

![两层且epoch=20](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/100795f5f20cc3a6ac19917d22f7d0bf77886422/picture/4.2.2%E4%B8%A4%E5%B1%82hidden64epoch%3D20.png)

### 3. 改变学习速率会如何影响结果？保持模型架构和其他超参数（包括轮数）不变，学习率设置为多少会带来最好的结果？
> 前几节做过这类实验，有个总结是：学习率太大，无法训练，学习率适当增大，能够使模型尽快收敛，学习率太小，收敛太慢。

examp：两层hiddens，256和64，epoch=20，lr=0.2

![两层hiddens，256和64，epoch=20，lr=0.2](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/dd249a7c0c14dd207ab58149f46501551e6d1249/picture/4.2.3%E4%B8%A4%E5%B1%82hiddens256%E5%92%8C64epoch%3D20lr%3D0.2.png)

> 两层hiddens，256和64，epoch=20，lr=0.2比两层hiddens，256和64，epoch=20，lr=0.1效果好
### 4. 通过对所有超参数（学习率、轮数、隐藏层数、每层的隐藏单元数）进行联合优化，可以得到的最佳结果是什么？
暂未得到最完美的

到目前为止，我做的最好的是两层hiddens，256和64，epoch=20，lr=0.2。
### 5. 描述为什么涉及多个超参数更具挑战性。
参数越多，需要优化的过程更长，增加计算量的同时，还有增加迭代次数，否则很难收敛。

### 6. 如果想要构建多个超参数的搜索方法，请想出一个聪明的策略。


## 4_3课后题
### 尝试添加不同数量的隐藏层（也可以修改学习率），怎么样设置效果最好？
参考4.2节课后题

### 尝试不同的激活函数，哪个效果最好？
> 评论区有人说：Sigmoid看上去更好，波动小，准确率高。
>
> 但经过我实验证明，他是最垃圾的，相比，tanh和relu都比她好，不分伯仲。如果非得选一个最好的，tanh。（评论区也有人和我相同观点）

1. RELU()

![RELU](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/ca1a35087efa6fdabeb6d502f5db8c2985a5c1a9/picture/4.3.2relu.png)

2. Sigmoid()

![sigmoid](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/ca1a35087efa6fdabeb6d502f5db8c2985a5c1a9/picture/4.3.2sigmoid.png)

3. tanh()

![tanh](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/ca1a35087efa6fdabeb6d502f5db8c2985a5c1a9/picture/4.3.2tanh.png)
### 尝试不同的方案来初始化权重，什么方法效果最好？


## 4_4课后题

### 1. 这个多项式回归问题可以准确地解出吗？提示：使用线性代数。
假设我们有如下的多项式回归问题：我们要拟合一个二次多项式$ \( y = w_0 + w_1x + w_2x^2 \)$。我们有一些样本数据 $\( (x_1, y_1), (x_2, y_2), ..., (x_n, y_n) \)$，我们的目标是找到最优的参数 $\( w_0, w_1, w_2 \)$ 来拟合这个二次多项式。

首先，我们可以构建特征矩阵 \( P \)，其中每一行代表一个样本，每一列代表特征的不同阶数。对于二次多项式，我们有：

$$
\[
P = \begin{bmatrix}
1 & x_1 & x_1^2 \\
1 & x_2 & x_2^2 \\
\vdots & \vdots & \vdots \\
1 & x_n & x_n^2 \\
\end{bmatrix}
\]
$$

同时，我们有标签向量 $\( y \)$，其中每个元素 $\( y_i \)$ 是对应样本的输出值。

接着，我们可以使用最小二乘法求解线性方程组 $\( P^T Pw = P^T y \)$。这个方程组可以写成：

$$
\[
\begin{bmatrix}
1 & 1 & \cdots & 1 \\
x_1 & x_2 & \cdots & x_n \\
x_1^2 & x_2^2 & \cdots & x_n^2 \\
\end{bmatrix}
\begin{bmatrix}
w_0 \\
w_1 \\
w_2 \\
\end{bmatrix}
$$

=

$$
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n \\
\end{bmatrix}
\]
$$

解这个线性方程组可以得到最优的参数 $\( w_0, w_1, w_2 \)$。然后我们就可以使用这些参数来拟合二次多项式，得到最终的拟合结果。

在实际应用中，我们可以利用现有的数值计算库，比如NumPy，来求解这个线性方程组，例如使用 `numpy.linalg.solve` 函数。以下是一个简单的Python示例代码：

```python
import numpy as np

# 样本数据
X = np.array([1, 2, 3, 4, 5])  # 输入特征
y = np.array([2.1, 3.9, 7.2, 10.8, 17.1])  # 输出标签

# 构建特征矩阵
P = np.vstack([np.ones_like(X), X, X**2]).T

# 使用最小二乘法求解线性方程组
w = np.linalg.solve(P.T @ P, P.T @ y)

# 输出最优参数
print("最优参数 w0:", w[0])
print("最优参数 w1:", w[1])
print("最优参数 w2:", w[2])
```

这段代码会输出拟合的二次多项式的最优参数 $\( w_0, w_1, w_2 \)$。然后我们可以使用这些参数来进行预测或者绘制拟合曲线。

### 考虑多项式的模型选择。

1. 绘制训练损失与模型复杂度（多项式的阶数）的关系图。观察到了什么？需要多少阶的多项式才能将训练损失减少到0?
``` py
# 随着feature_num的增加 loss的变化
def train1(train_features,test_features,train_labels,
          test_labels,num_epochs= 400):
    loss = nn.MSELoss(reduction='none')
    input_shape = train_features.shape[-1]
    
    net = nn.Sequential(nn.Linear(input_shape,1,bias=False))
    batch_size = min(10,train_labels.shape[0])
    train_iter = d2l.load_array((train_features,
                                 train_labels.reshape(-1,1)),batch_size)
    test_iter = d2l.load_array((test_features,
                               test_labels.reshape(-1,1)),batch_size,is_train=False)

    trainer = torch.optim.SGD(net.parameters(),lr=0.01)
    for epoch in range(num_epochs):
        d2l.train_epoch_ch3(net, train_iter, loss, trainer)
        if epoch == 399:
            train_loss=evaluate_loss(net,train_iter,loss)
            test_loss = evaluate_loss(net,test_iter,loss)
            return train_loss,test_loss
            
import matplotlib.pyplot as plt

a = range(1,20)

animator = d2l.Animator(xlabel='feature_nums', ylabel='loss', yscale='log',
                            xlim=[1, 20], ylim=[1e-3, 1e2],
                            legend=['train', 'test'])
for i in a:
    c=0
    d=0
    c,d=train1(poly_features[:n_train,:i],poly_features[n_train:,:i],
         labels[:n_train],labels[n_train:])
    animator.add(i,(c,d))        
```


2. 在这种情况下绘制测试的损失图。

> 借用评论区的结论：随着 feature_nums 的增加模型的 loss 趋于稳定，虽然没有最低点nums=4效果好，​ 但是 误差已经很小了，测试集和训练集相差结果也不是很大，过拟合可以接受
>
> 本人不会画图，借鉴了一下
>
> 根据图像可以看出，当多项式特征取前四个维度时，损失最小，但此时仍未达到0。在图像左侧，训练损失远远大于测试损失，体现了欠拟合，右侧则表现出测试损失始终大于训练损失，体现了过拟合。

![feature_num=4时结果最好](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/fdbc81dbe4045d6fc9d60d522ea2bfddfb4fcd84/picture/4.4.2feature_num.png)

3. 生成同样的图，作为数据量的函数。
> 结论：  一开始明显过拟合 ，数据量太小 ，训练集误差小，测试集误差大；随着训练数据量的增加，训练集和测试集的loss 差距逐渐减小；80个epochs 后二者都趋于平稳
>
> 可能会发生上溢出 ， 超过数据表示范围 ，而且数据太大也不利于计算
>
> 误差误差，泛化误差和训练误差都不可能为0(除非只有一个样本，训练误差为0)

``` py
def train2(train_features,test_features,train_labels,
          test_labels,num_epochs=400):
    loss = nn.MSELoss(reduction='none')
    input_shape = train_features.shape[-1]
    
    net = nn.Sequential(nn.Linear(input_shape,1,bias=False))
    batch_size = min(10,train_labels.shape[0])
    train_iter = d2l.load_array((train_features,
                                 train_labels.reshape(-1,1)),batch_size)
    test_iter = d2l.load_array((test_features,
                               test_labels.reshape(-1,1)),batch_size,is_train=False)

    trainer = torch.optim.SGD(net.parameters(),lr=0.01)
    for epoch in range(num_epochs):
        d2l.train_epoch_ch3(net, train_iter, loss, trainer)
        if epoch == (num_epochs-1):
            return evaluate_loss(net, train_iter, loss),evaluate_loss(net, test_iter, loss)




b= range(1,n_train)

anm = d2l.Animator(xlabel='data_nums',ylabel='loss',yscale='log',
                   xlim=[1,n_train],ylim=[1e-3, 1e2],
                  legend=['train','test'])
for i in b:
    c=0
    d=0
    c,d = train2(poly_features[:i,:4],poly_features[n_train:,:4],
                 labels[:i],labels[n_train:])
    anm.add(i,(c,d))
```

![loss](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/fdbc81dbe4045d6fc9d60d522ea2bfddfb4fcd84/picture/4.4.2floss.png)

### 3. 如果不对多项式特征$x^i$进行标准化($1/i!$)，会发生什么事情？能用其他方法解决这个问题吗？

![不标准化](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/fdbc81dbe4045d6fc9d60d522ea2bfddfb4fcd84/picture/4.4.3%E4%B8%8D%E6%A0%87%E5%87%86%E5%8C%96.png)

如果不除以阶乘，那么很有可能会出现指数（上或下）溢出 导致结果出现nan。我的解决思路是对每一项取log

### 4. 泛化误差可能为零吗？
在实际情况下，泛化误差（generalization error）通常不会为零。泛化误差指的是模型在未见过的数据上的误差，也可以理解为模型对于新数据的预测能力。即使一个模型在训练集上表现非常好（训练误差低），也不代表它的泛化误差为零。

数据噪声：现实世界的数据通常包含噪声，即使是对于同一输入，也可能存在不同的输出。模型在训练过程中可能会过拟合这些噪声，导致泛化误差不为零。


## 4_5课后题

### 1. 在本节的估计问题中使用 $ \lambda $ 的值进行实验。绘制训练和测试精度关于 $ \lambda $ 的函数。观察到了什么？
> 先急速收缩，再不断震荡

``` py
#2024-4-21
#刘昊阳

def train(wd):
    net = nn.Sequential(nn.Linear(num_inputs, 1))  # 定义网络
    for param in net.parameters():
        param.data.normal_()  # 初始化参数
    loss = nn.MSELoss(reduction='none')  # 损失
    num_epochs, lr = 100, 0.003
    # 设置参数衰减
    trainer = torch.optim.SGD([
        {'params':net[0].weight, 'weight_decay':wd},
        {'params':net[0].bias}], lr=lr)
    for epoch in range(num_epochs):
        for X, y in train_iter:
            trainer.zero_grad()
            l = loss(net(X), y)
            l.mean().backward()
            trainer.step()
    return d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss)
    # print('w的L2范数：', net[0].weight.norm().item())

max_wd = 100
animator = d2l.Animator(xlabel='wd', ylabel='loss', yscale='log', xlim=[0, max_wd], legend=['train', 'test'])
for wd in range(max_wd+1):
    l_train, l_test = train(wd)
    animator.add(wd, (l_train, l_test))
```

![不同lamda下的loss]()

### 使用验证集来找到最佳值  $ \lambda $ 。它真的是最优值吗？这有关系吗？
不是。它是相对于这个训练集和测试机的最优值。如果数据集的大小改变，那么这个λ 值也会随之改变。

### 如果我们使用  $\sum_i |w_i|$ 作为我们选择的惩罚（ $L_1$  正则化），那么更新方程会是什么样子？
相对于 $w^2$,绝对值的影响使其导数w项恒为正，见下图

![ $\sum_i |w_i|$]()

### 我们知道 $\|\mathbf{w}\|^2 = \mathbf{w}^\top \mathbf{w}$ 。能找到类似的矩阵方程吗（见 2.3.10节 中的Frobenius范数）？

在线性代数中，对于向量的范数有一个类似的矩阵范数，即弗罗贝尼乌斯范数（Frobenius norm）。弗罗贝尼乌斯范数用于衡量矩阵的大小，定义如下：

给定一个矩阵 $\( A \)$ ，它的弗罗贝尼乌斯范数 $\( \| A \|_F \)$ 定义为矩阵中所有元素的平方和的平方根，即：

$$
\[ \| A \|_F = \sqrt{\sum_{i=1}^{m} \sum_{j=1}^{n} |a_{ij}|^2} \]
$$

其中，$\( a_{ij} \)$ 表示矩阵 $\( A \)$ 的第 $\( i \)$ 行第 $\( j \)$ 列的元素。

类似于向量范数的平方形式 $\( \| \mathbf{w} \|^2 = \mathbf{w}^\top \mathbf{w} \)$，我们也可以写出矩阵范数的平方形式：

$$
\[ \| A \|_F^2 = \sum_{i=1}^{m} \sum_{j=1}^{n} |a_{ij}|^2 = \text{Tr}(A^\top A) \]
$$

其中，$\( \text{Tr}(A) \)$ 表示矩阵 $\( A \)$ 的迹（trace），即主对角线上元素的和。这个形式和向量的平方范数类似，但是应用于矩阵的情况。

### 回顾训练误差和泛化误差之间的关系。除了权重衰减、增加训练数据、使用适当复杂度的模型之外，还能想出其他什么方法来处理过拟合？
> 综合GPT和个人和评论区答案
除了权重衰减、增加训练数据和使用适当复杂度的模型之外，还有一些其他方法可以处理过拟合问题。这些方法包括：

1. **早停（Early Stopping）**：在训练过程中监控验证集的误差，一旦验证集误差开始上升，则停止训练。这可以防止模型在训练集上过度拟合。

2. **Dropout**：在训练过程中随机地将一部分神经元设置为0，以减少神经网络的复杂度和过拟合的风险。在测试时，通常不使用Dropout。

3. **数据增强（Data Augmentation）**：通过对训练数据进行一系列随机变换（如旋转、缩放、平移等），生成新的训练样本，从而扩大训练数据集的规模，减少过拟合。

4. **集成学习（Ensemble Learning）**：使用多个不同的模型或同一模型的不同版本进行训练，并将它们的预测结果进行组合，以降低泛化误差。常见的集成方法包括Bagging、Boosting和Stacking。

5. **正则化方法**：除了权重衰减外，还可以使用其他正则化方法，如L1正则化（Lasso）和L2正则化（Ridge），来限制模型参数的大小，防止过拟合。

6. **交叉验证（Cross-Validation）**：通过将数据集划分为多个子集，在不同的子集上进行训练和验证，从而更准确地评估模型的性能和泛化能力，避免仅依赖于单次验证的不确定性。

## 4_6课后题
#### 如果更改第一层和第二层的暂退法概率，会发生什么情况？具体地说，如果交换这两个层，会发生什么情况？设计一个实验来回答这些问题，定量描述该结果，并总结定性的结论。
> 交换两个层，一开始是0.2 0.5 后0.5 0.2，变稳定了

交换前：

![交换前](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/eb48427068e027ea5108dbbb098604aa5462cc49/picture/4.6.1%E4%BA%A4%E6%8D%A2%E5%89%8D.png)

交换后：

![交换后](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/eb48427068e027ea5108dbbb098604aa5462cc49/picture/4.6.1%E4%BA%A4%E6%8D%A2%E5%90%8E.png)
#### 增加训练轮数，并将使用暂退法和不使用暂退法时获得的结果进行比较。
原始：epoch=10

![交换前](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/eb48427068e027ea5108dbbb098604aa5462cc49/picture/4.6.1%E4%BA%A4%E6%8D%A2%E5%89%8D.png)

增加epoch=20

![增加epoch=20](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/eb48427068e027ea5108dbbb098604aa5462cc49/picture/4.6.1%E4%BA%A4%E6%8D%A2%E5%89%8D.png)

不使用暂退法

![不使用暂退法](https://github.com/Sheibyer/Introduction-to-machine-learning/blob/eb48427068e027ea5108dbbb098604aa5462cc49/picture/4.6.1%E4%BA%A4%E6%8D%A2%E5%89%8D.png)

#### 当应用或不应用暂退法时，每个隐藏层中激活值的方差是多少？绘制一个曲线图，以显示这两个模型的每个隐藏层中激活值的方差是如何随时间变化的。

#### 为什么在测试时通常不使用暂退法？
测试不改变模型。测试时模型已经训练好，暂退法是用来完善模型的，所以猜丢弃某些节点。
#### 以本节中的模型为例，比较使用暂退法和权重衰减的效果。如果同时使用暂退法和权重衰减，会发生什么情况？结果是累加的吗？收益是否减少（或者说更糟）？它们互相抵消了吗？
同时使用暂退法和权重衰减的收益确实是累加的，会比单独使用好一些。

对于暂退法和权重衰减的比较来说，还需要调整学习率等参数才能实现更好的效果。

借用上面大佬的话说，暂退法是引入一定的噪声，增加模型对输入数据的扰动鲁棒，从而增强泛化；权重衰减在于约束模型参数防止过拟合。
#### 如果我们将暂退法应用到权重矩阵的各个权重，而不是激活值，会发生什么？

#### 发明另一种用于在每一层注入随机噪声的技术，该技术不同于标准的暂退法技术。尝试开发一种在Fashion-MNIST数据集（对于固定架构）上性能优于暂退法的方法。


### 4_8_课后题

#### 4.8.1除了多层感知机的排列对称性之外，还能设计出其他神经网络可能会表现出对称性且需要被打破的情况吗？

后续学了其他神经网络再来回答此问题

#### 4.8.2我们是否可以将线性回归或softmax回归中的所有权重参数初始化为相同的值？

不行！！！  

在线性回归或 softmax 回归中，通常情况下不建议将所有权重参数初始化为相同的值。这是因为如果所有权重参数初始值相同，那么它们在模型训练的过程中会以相同的方式更新，这可能导致模型无法学习到复杂的模式和特征。

具体来说，如果所有权重初始化为相同的值，那么无论输入数据如何变化，模型在每一层中都会得到相同的梯度。这样的情况会导致模型无法区分不同的特征或类别，从而降低模型的表达能力和泛化能力。

为了避免这种情况，通常会采用不同的初始化策略，比如使用随机初始化来打破**对称性**，或者使用预训练模型来初始化参数。这样可以确保模型在训练过程中能够充分利用数据的特征，提高模型的性能和泛化能力。

#### 4.8.3在相关资料中查找两个矩阵乘积特征值的解析界。这对确保梯度条件合适有什么启示？
    假设我们有一个线性回归模型，其中的权重矩阵为 $\( W \)$ ，输入数据的矩阵为 $\( X \)$ ，输出数据的矩阵为 $ \( Y \)$。那么线性回归模型可以表示为 $\( Y = XW \)$ 。

在这个例子中，我们可以考虑特征值解析界对梯度条件的影响。假设我们使用梯度下降算法来训练模型，损失函数为均方误差（Mean Squared Error）。

1. **条件数过大**：如果权重矩阵 $\( W \)$ 的特征值解析界较小，即条件数较大，可能导致梯度在更新过程中不稳定。例如，某些特征值较大，而另一些特征值较小，这会导致梯度方向在不同特征上变化很大，可能出现梯度爆炸或梯度消失的情况。

2. **条件数适中**：如果权重矩阵 $\( W \)$ 的特征值解析界适中，即条件数适中，梯度在更新过程中更加稳定。例如，特征值相对均衡，梯度的方向变化较为平稳，有助于模型收敛到较好的解。


综上所述，通过合理设置模型的初始化方法、正则化策略和学习率调整策略，可以有效地控制特征值解析界，从而提高模型的性能和泛化能力。
#### 4.8.4如果我们知道某些项是发散的，我们能在事后修正吗？看看关于按层自适应速率缩放的论文 (You et al., 2017) 。

在深度学习中，如果在训练过程中发现某些项发散（例如梯度爆炸），可以采取一些方法来进行事后修正以确保模型训练的稳定性和收敛性。论文 "按层自适应速率缩放"（Layer-Wise Adaptive Rate Scaling）由 You 等人于2017年发表，提出了一种自适应地调整学习率的方法，用于处理梯度爆炸和梯度消失等问题。

该方法的核心思想是根据每一层的梯度范数来自适应地调整学习率，以确保每一层的梯度更新在合适的范围内，防止梯度爆炸或梯度消失的问题。

具体来说，按层自适应速率缩放的方法可以分为以下几个步骤：

1. **计算每一层的梯度范数**：在每一次训练迭代中，计算每一层的梯度范数。

2. **计算调整系数**：根据每一层的梯度范数，计算调整系数，用于调整该层的学习率。通常采用一定的规则或公式来计算调整系数。

3. **调整学习率**：根据计算得到的调整系数，对每一层的学习率进行调整，以确保梯度更新在合适的范围内。

4. **继续训练**：使用调整后的学习率继续进行模型训练，直到收敛或达到预设的训练轮数。

按层自适应速率缩放的方法能够有效地处理梯度发散的问题，并且在一定程度上提高了模型的训练效率和稳定性。这种方法的优势在于可以针对每一层的梯度情况进行自适应地调整学习率，避免了全局统一的学习率调整可能带来的问题。

需要注意的是，虽然按层自适应速率缩放可以有效处理梯度发散的问题，但在实际应用中，还需要结合其他技术和策略来综合提高模型的性能和泛化能力。
